{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41abbff3-f956-4a86-80db-b5cc925877ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f51672b-0da2-4387-be11-0033300515b3",
   "metadata": {},
   "source": [
    "### Background\n",
    "the Hierarchical Clustering is a tree-based approach of implementation of clustering process. Unlike Divisive Clustering, the Agglomerative Hierarchical Clustering (HAC) using bottom-up approach and in the first step of the algorithm each object is considered as a single cluster. In each step of the algorithm, the most similar two clusters (based on defined distance measure) are combined into a new cluster.\n",
    "\n",
    "Agglomerative clustering is one of the oldest and most used strategies for handling clustering process. It has many applications including anomaly detection and bioinformatics applications. One of the important tasks of agglomerative clustering is to specify a distance measure between clusters. In this notebook, we used complete linkage strategy for the distance measures. According to the complete linkage strategy, the distance between pair of clusters is defined as the distance between their furthest pair of data objects.  It is important to note that there are wide range of strategies for specifying the distance between two clusters in agglomerative clustering. \n",
    "\n",
    "Agglomerative clustering has a very big advantage that it is very ease to do and to understand. In addition, the dendrogram is a common visual tool for showing the hierarchical clustering as a tree diagram. However, not everything is positive with agglomerative clustering. One of the main disadvantages of this algorithm is that it requires a huge storage, a large time complexity, and it rarely provides the best solution. It is very difficult to perform hierarchical clustering on very large datasets because of the time complexity O(kn2) where k is the number of clusters and n is the number of inputs to be clustered. In addition, it is a greedy algorithm and once we created a cluster, we “can’t go back”.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d0fb1-4051-4935-8342-fddd762cf3e7",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888fc1e-2ff7-460c-89d1-88a5573bf1d8",
   "metadata": {},
   "source": [
    "In this notebook, we have written a general approach to implement Hierarchial Agglomerative Clustering (HAC). \n",
    "\n",
    "We have used *Complete Linkeage Strategy* as the distance measure between two clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b633cf-b8bd-4c11-a937-476ac45e1e04",
   "metadata": {},
   "source": [
    "### Rules\n",
    "\n",
    "We have defined a set of assumptions and rules that should be followed:\n",
    "\n",
    "-> The input is a Python dictionary that maps object ID (integer) to 1D array\n",
    "\n",
    "-> Distance function should be configurable - by default the distance between pair of clusters is based on the *Complete Linkeage Strategy*\n",
    "\n",
    "-> The expected result is set of tuples that each one of them includes the IDs of the objects within that cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159d520-8da3-471f-9bcf-e355c6f349f7",
   "metadata": {},
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1289e62-bc92-43dc-b39e-b73055ec8e2d",
   "metadata": {},
   "source": [
    "First, let's import the libraries nesessary for this notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "a93d1839-fb96-4048-86ed-e1a340f387f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy which is the single important library for this algorithm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66e11e3-3218-4128-a4a7-0a542d7c15e3",
   "metadata": {},
   "source": [
    "### Create Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74f2736-4056-4fe8-90a0-850b8046a521",
   "metadata": {},
   "source": [
    "In case you already have data, you can load it and skip this part. However, please make sure you follow the required data structure for the next phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "fd3a4940-8ed9-4f98-938b-9b08e8e4262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just initilized 5 inputs, each from 10 dimension\n"
     ]
    }
   ],
   "source": [
    "# for a given values of array size and number of clusters, the following method generates a random input\n",
    "def create_input(array_size=10, clusters=5):\n",
    "    np.random.seed(5)\n",
    "    points = {}\n",
    "    for i in range(clusters):\n",
    "        points[i] = np.random.rand(array_size, )\n",
    "    print('We just initilized {} inputs, each from {} dimension'.format(clusters, array_size))\n",
    "    return points\n",
    "points = create_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04d5cb-801b-4468-b605-924c03e11908",
   "metadata": {},
   "source": [
    "let's examine one of the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "f0e5633a-16da-4301-a836-62fadb29960e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22199317, 0.87073231, 0.20671916, 0.91861091, 0.48841119,\n",
       "       0.61174386, 0.76590786, 0.51841799, 0.2968005 , 0.18772123])"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156bc39a-291e-483f-b81b-8c9ef5b45d98",
   "metadata": {},
   "source": [
    "### Distance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ff1d8-46a9-41c8-991b-c60539a3c693",
   "metadata": {},
   "source": [
    "As mentioned above, you need to specify a distance measure for the agglomerative clustering. We decided to use Complete Linkage Strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "f0355906-5d4f-4f1e-9757-fd563786b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between two arrays\n",
    "def calculate_distance(p1, p2):\n",
    "    a1, b1 = min(p1), max(p1)\n",
    "    a2, b2 = min(p2), max(p2)\n",
    "    return max(abs(b2-a1), abs(b1-a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8195d0-15c3-4155-8556-42a024ca4f97",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9d73b-eb42-4b55-aace-9867bbccc2a2",
   "metadata": {},
   "source": [
    "The following code cells includes two general flow of the algorithm as we defined. Important notes:\n",
    "- We only need to calculate the distances in the first step of the algorithm. The distance between an \"old cluster\" and a \"new cluster\" is basically the maximum distance between the \"old cluster\" and the two \"old clusters\" the combines the \"new cluster\". In other words, we already have that distance and we don't need to calculate it again.\n",
    "- Throughout the algorithm, we keep two important objects: \n",
    "    - clusters: set of tuples that represents the current clusters\n",
    "    - points_dist: dictionary that stores the distances between each pair of clusters in the current phase\n",
    "- In each iteration, we update both the list of current clusters and the dictionary of distances between clusters.\n",
    "- Assuming that the k (number of clusters) is lower than n (the number of observations), we need to go through n-k iterations to achieve k clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "e0eb1f29-1fe5-46d7-b20b-4ae69f4e12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_points_dist(points_dist,clusters, new_cluster):\n",
    "    '''  Update of the distance dictionary.\n",
    "    Note that we delete the \"old pairs\" that are not important anymore.'''\n",
    "    \n",
    "    # Pulling out the clusters that are being merged\n",
    "    old_cluster_a = new_cluster[0]\n",
    "    old_cluster_b = new_cluster[1]\n",
    "    \n",
    "    # Iterate through the list of current clusters, delete unimportant pairs from the distance dictinoary\n",
    "    # In addition, find and update the maximum value between each \"old cluster\" and the \"new cluster\"\n",
    "    for c3 in clusters:\n",
    "        if ((c3),(old_cluster_a)) in points_dist.keys():\n",
    "            value =  points_dist[(c3),(old_cluster_a)]\n",
    "            del points_dist[(c3),(old_cluster_a)]\n",
    "        else:\n",
    "            value =  points_dist[(old_cluster_a),(c3)]\n",
    "            del points_dist[(old_cluster_a),(c3)]\n",
    "        if ((c3),(old_cluster_b)) in points_dist.keys():\n",
    "            value =  max(value, points_dist[(c3),(old_cluster_b)])\n",
    "            del points_dist[(c3),(old_cluster_b)]\n",
    "        else:\n",
    "            value =  max(value, points_dist[(old_cluster_b),(c3)])\n",
    "            del points_dist[(old_cluster_b),(c3)]\n",
    "            \n",
    "        # Create a new pair in distance dictionary between the \"old cluster\" and the \"new cluster\"\n",
    "        points_dist[old_cluster_a+old_cluster_b, c3] = value\n",
    "    \n",
    "    # delete the combintation of the two clusters that represents the \"new clusters\" since we don't need them anymore\n",
    "    del points_dist[new_cluster]\n",
    "    \n",
    "    # return the updated distance dictionary\n",
    "    return points_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "2dcc22b5-03ef-4117-8930-b78250ef2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerative_clustering(points, k=5):\n",
    "    ''' Perform agglomerative clustering for \n",
    "    a given dictionary of points and hyperparameter k (number of clusters). '''\n",
    "        \n",
    "    # First step: convert all the clusters into a set of tuples\n",
    "    clusters = list(zip(points.keys()))\n",
    "    \n",
    "    # If the required K is similar or above the number of initial clusters then we done\n",
    "    if k >= len(clusters):\n",
    "        return clusters\n",
    "    \n",
    "    # Create the dictionary of distances between each pair of clusters. Again, we only need to do that in this phase.\n",
    "    points_dist = {}\n",
    "    for c1 in clusters:\n",
    "        for c2 in clusters:\n",
    "            if (c1,c2) not in list(points_dist.keys()) and (c2,c1) not in list(points_dist.keys()) and c1!= c2:\n",
    "                points_dist[(c1, c2)] = calculate_distance(points[c1[0]], points[c2[0]])\n",
    "                \n",
    "    # Perform the clustering process until we achieve K clusters (in total n-K iterations)\n",
    "    # Note that in each iteration, we remove two clusters and add a new cluster\n",
    "    while k < len(clusters):\n",
    "        new_cluster = min(points_dist, key=points_dist.get)\n",
    "        clusters.remove(new_cluster[0])\n",
    "        clusters.remove(new_cluster[1])\n",
    "        points_dist = update_points_dist(points_dist, clusters, new_cluster)\n",
    "        clusters.append(new_cluster[0]+new_cluster[1])\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "d7b094eb-c198-401b-a185-18b1e2f5e7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_clusters= agglomerative_clustering(points, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "4dd209cf-ebdc-469e-a770-204982011fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3,), (0, 2, 1, 4)]"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
